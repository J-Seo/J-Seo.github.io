---
layout: post
title: "The Impact of Negated Text on Hallucination with Large Language Models"
date: 2025-08-21
image: "https://raw.githubusercontent.com/J-Seo/J-Seo.github.io/main/assets/img/emnlp2025.png"
Journal: EMNLP 2025
authors: Jaehyung Seo, Hyeonseok Moon, Heuiseok Limâ€ 
categories: outstanding
star: ðŸŒŸ
---
**Authors**
- **Jaehyung Seo**, Hyeonseok Moon, Heuiseok Limâ€ 

**Abstract**

Recent studies on hallucination in large language models (LLMs) have been actively progressing in natural language processing. However, the impact of negated text on hallucination with LLMs remains largely unexplored. In this paper, we set three important yet unanswered research questions and aim to address them. To derive the answers, we investigate whether LLMs can recognize contextual shifts caused by negation and still reliably distinguish hallucinations comparable to affirmative cases. We also design the NegHalu dataset by reconstructing existing hallucination detection datasets with negated expressions. Our experiments demonstrate that LLMs struggle to detect hallucinations in negated text effectively, often producing logically inconsistent or unfaithful judgments. Moreover, we trace the internal state of LLMs as they process negated inputs at the token level and reveal the challenges of mitigating their unintended effects.

Check out the [This Link][DOI] for more info on our paper

[DOI]: https://openreview.net/forum?id=VnLhUogHYE

