---
layout: post
title: "Find the Intention of Instruction: Comprehensive Evaluation of Instruction Understanding for Large Language Models"
date: 2025-02-01
image: "https://raw.githubusercontent.com/J-Seo/J-Seo.github.io/main/assets/img/naacl2025.png"
Journal: NAACL 2025 - Findings
authors: Hyeonseok Moon, Jaehyung Seo, Seungyoon Lee, Chanjun Park, Heuiseok Lim
categories: outstanding
---
**Authors**
- Hyeonseok Moon, **Jaehyung Seo**, Seungyoon Lee, Chanjun Park, Heuiseok Lim

**Abstract**

Through numerous endeavors, large language models (LLMs) have witnessed significant advancements in their instruction-following capability. However, we discern that LLMs are prone to generate responses to instruction-formatted statements in an instinctive manner, rather than comprehending the underlying user intention reside within the given instructions. We also recognize that the significance of instruction understanding capability is largely overlooked in most of LLM evaluation benchmarks. To ensure more comprehensive evaluation on the instruction understanding capability of LLM, we propose Intention of Instruction (IntInst) benchmark, which primary objective is to distinguish the appropriate instruction that accurately instruct to generate a given context. IntInst presents four instruction candidates and requires LLMs to select one among them. Through extensive experiments with several instruction-tuned LLMs, we reveal that most LLMs struggle to grasp the actual intention concealed in the instruction and thoroughly analyze the factors influencing instruction understanding.

Check out the [This Link][DOI] for more info on our paper

[DOI]: https://arxiv.org/abs/2412.19450

