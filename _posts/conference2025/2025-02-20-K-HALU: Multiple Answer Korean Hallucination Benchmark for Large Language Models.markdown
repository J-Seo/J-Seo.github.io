---
layout: post
title: "K-HALU: Multiple Answer Korean Hallucination Benchmark for Large Language Models"
date: 2025-02-20
image: "https://raw.githubusercontent.com/J-Seo/J-Seo.github.io/main/assets/img/iclr2025.png"
Journal: ICLR 2025
authors: Jaehyung Seo, Heuiseok Lim*
categories: outstanding
star: ðŸŒŸ
---
**Authors**
- **Jaehyung Seo**, Heuiseok Lim<sup>*</sup>

**Abstract**

Recent researchers and companies have been developing large language models (LLMs) specifically designed for particular purposes and have achieved significant advancements in various natural language processing tasks. However, LLMs are still prone to generating hallucinationsâ€”results that are unfaithful or inconsistent with the given input. As a result, the need for datasets to evaluate and demonstrate the hallucination detection capabilities of LLMs is increasingly recognized. Nonetheless, the Korean NLP community lacks publicly available benchmark datasets demonstrating the faithfulness of knowledge-based information. Furthermore, the few existing datasets that evaluate hallucination are limited in their access to the entire dataset, restricting detailed analysis beyond simple scoring, and are based on translated English knowledge. To address these challenges, we introduce K-HALU, a Korean benchmark designed to evaluate LLMs' hallucination detection in Korean. This benchmark contains seven domains, considering the faithfulness of statements based on knowledge documents compiled from Korean news, magazines, and books. For more strict evaluation, 40% of the dataset is structured as multiple-answer questions, requiring models to select all possible correct answers from the given options. Our empirical results show that open-source LLMs still struggle with hallucination detection in Korean knowledge, emphasizing the need for a more detailed analysis of their limitations.

Check out the [This Link][DOI] for more info on our paper

[DOI]: https://openreview.net/forum?id=VnLhUogHYE

