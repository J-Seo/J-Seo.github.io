---
layout: post
title: "Generative Interpretation: Toward Human-Like Evaluation for Educational Question-Answer Pair Generation"
date: 2024-03-17
Journal: EACL 2024 - Findings
image: "https://raw.githubusercontent.com/J-Seo/J-Seo.github.io/main/assets/img/eacl2024.png"
categories: outstanding
authors: Hyeonseok Moon, Jaewook Lee, Sugyeong Eo, Chanjun Park*, Jaehyung Seo, Heuiseok Lim*
---
**Authors**
- Hyeonseok Moon, Jaewook Lee, Sugyeong Eo, Chanjun Park<sup>*</sup>, **Jaehyung Seo**, Heuiseok Lim<sup>*</sup>

**Abstract**
Educational question-answer generation has been extensively researched owing to its practical applicability. However, we have identified a persistent challenge concerning the evaluation of such systems. Existing evaluation methods often fail to produce objective results and instead exhibit a bias towards favoring high similarity to the ground-truth question-answer pairs. In this study, we demonstrate that these evaluation methods yield low human alignment and propose an alternative approach called Generative Interpretation (GI) to achieve more objective evaluations. Through experimental analysis, we reveal that GI outperforms existing evaluation methods in terms of human alignment, and even shows comparable performance with GPT3.5, only with BART-large.

Check out the [This Link][DOI] for more info on our paper

[DOI]: https://aclanthology.org/2024.findings-eacl.145.pdf

